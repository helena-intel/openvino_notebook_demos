{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training to Deployment with PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T20:07:23.645891Z",
     "iopub.status.busy": "2022-01-17T20:07:23.645722Z",
     "iopub.status.idle": "2022-01-17T20:07:23.647837Z",
     "shell.execute_reply": "2022-01-17T20:07:23.647609Z",
     "shell.execute_reply.started": "2022-01-17T20:07:23.645847Z"
    }
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Horea94/Fruit-Images-Dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to directory with data, with one subdirectory per category\n",
    "DATADIR = \"Fruit-Images-Dataset\"\n",
    "# Shape to resize the images to before propagating through the network. For MobileNet this is (224,224).\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "# Descriptive name of the model. Saved models will be named MODELNAME.onnx etc.\n",
    "MODELNAME = \"fruit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "import time\n",
    "import warnings\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import sklearn.metrics as skm\n",
    "import torch\n",
    "import torchmetrics as metrics\n",
    "import torchvision\n",
    "from openvino.inference_engine.ie_api import IECore\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as TorchDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseDataset(TorchDataset):\n",
    "    \"\"\"\n",
    "    DataLoader for image data that is stored in a directory per category. For example, for\n",
    "    categories _rose_ and _daisy_, rose images are expected in data_source/rose, daisy images\n",
    "    in data_source/daisy.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source, split, transforms=None):\n",
    "        \"\"\"\n",
    "        :param data_source: path to data directory\n",
    "        \"\"\"\n",
    "        self.data_source = Path(data_source) / split\n",
    "        assert self.data_source.is_dir(), f\"{self.data_source} is not a directory\"\n",
    "        self.dataset = [p for p in self.data_source.glob(\"**/*\") if p.suffix in (\".png\", \".jpg\")]\n",
    "        self.class_names = sorted(\n",
    "            [item.name for item in Path(self.data_source).iterdir() if item.is_dir()]\n",
    "        )\n",
    "        self.num_classes = len(self.class_names)\n",
    "        self.split = split\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of elements in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get item from self.dataset at the specified index.\n",
    "        \"\"\"\n",
    "        if index >= len(self):\n",
    "            raise IndexError\n",
    "        filepath = self.dataset[index]\n",
    "        annotation = self.class_names.index(filepath.parent.name)\n",
    "        image = self._read_image(str(filepath))\n",
    "        return torch.as_tensor(image), torch.as_tensor(annotation)\n",
    "\n",
    "    def _read_image(self, filepath):\n",
    "        \"\"\"\n",
    "        Read image at dataset[index] to memory, resize, convert to BGR and to network shape\n",
    "\n",
    "        :param index: dataset index to read\n",
    "        :return ndarray representation of image batch\n",
    "        \"\"\"\n",
    "        image = cv2.imread(filepath)[:, :, (2, 1, 0)]\n",
    "        image = cv2.resize(image, IMAGE_SHAPE).astype(np.float32)\n",
    "        return image.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str, batch_size):\n",
    "        print(data_dir)\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.data_dir = data_dir\n",
    "        # self.setup()\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset_train = BaseDataset(self.data_dir, \"Training\")\n",
    "        self.dataset_val = BaseDataset(self.data_dir, \"Test\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset_train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset_val, batch_size=self.batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LightningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InceptionLightningModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes, aux_logits):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "        self.num_classes = num_classes\n",
    "        self.aux_logits = aux_logits\n",
    "\n",
    "        # Replace last layer with classifier for number of classes in dataset\n",
    "        num_ftrs = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = torch.nn.Linear(\n",
    "            in_features=num_ftrs, out_features=num_classes, bias=True\n",
    "        )\n",
    "        self.metric = metrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.long()\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.CrossEntropyLoss()(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        p = self(x)\n",
    "        ytrue = y.long().flatten()\n",
    "        ypred = torch.argmax(p, dim=1).long().flatten()\n",
    "        score = self.metric(ytrue.cpu(), ypred.cpu())\n",
    "        return {\n",
    "            \"metric\": score,\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        metric_mean = torch.stack([x[\"metric\"] for x in validation_step_outputs]).mean()\n",
    "        self.log(\"validation_accuracy\", metric_mean, prog_bar=True, logger=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the train dataset\n",
    "\n",
    "Show the train dataset to check that the data looks okay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = DataModule(DATADIR, 32)\n",
    "data.setup()\n",
    "\n",
    "num = min(len(data.dataset_train), 10)\n",
    "indices = random.sample(range(len(data.dataset_train)), num)\n",
    "data_subset = itemgetter(*indices)(data.dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, num, figsize=(20, 4), squeeze=False)\n",
    "for i, (image, label) in enumerate(data_subset):\n",
    "    ax[0, i].imshow(image.short().permute(1, 2, 0).cpu())\n",
    "    ax[0, i].set_title(f\"{data.dataset_val.class_names[label]}\")\n",
    "    ax[0, i].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train the model\n",
    "\n",
    "We train the model for five epochs. Since the model uses weights pretrained on ImageNet, this should give good performance if the data is similar to ImageNet data. For other data, you will probably need to increase the `num_epochs` parameter of PyTorch Lightning's `Trainer`. Set `gpus` to `0` if you do not want to use a GPU for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"tb_logs\", name=MODELNAME)\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"validation_accuracy\", mode=\"max\", save_top_k=1)\n",
    "# Ignore PyTorch Lightning warnings about possible improvements\n",
    "warnings.filterwarnings(\"ignore\", \".*Consider increasing the value of the `num_workers` argument*\")\n",
    "model = InceptionLightningModel(num_classes=data.dataset_train.num_classes, aux_logits=False)\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    gpus=1 if USE_CUDA else 0,\n",
    "    logger=logger,\n",
    "    precision=16 if USE_CUDA else 32,\n",
    "    limit_train_batches=0.2,\n",
    "    limit_val_batches=0.2,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    fast_dev_run=False,  # set to True to quickly test the Lightning model\n",
    ")\n",
    "\n",
    "trainer.fit(model=model, datamodule=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model on the validation dataset\n",
    "\n",
    "The PyTorch Lightning `.validate()` method loads the best checkpoint (the checkpoint with the highest accuracy) into the model and returns the accuracy over the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.validate(model, datamodule=data, ckpt_path=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions on validation dataset\n",
    "\n",
    "Metrics do not always tell the whole story. Visualizing the results also helps to understand the quality of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viz_dataset = data.dataset_val\n",
    "num = min(len(viz_dataset), 6)\n",
    "indices = np.random.choice(range(len(viz_dataset)), num, replace=False)\n",
    "\n",
    "fig, ax = plt.subplots(1, num, figsize=(20, 5), squeeze=False)\n",
    "model.eval().cpu()\n",
    "for i, index in enumerate(indices):\n",
    "    image, label = viz_dataset[index]\n",
    "    image = torch.as_tensor(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image.unsqueeze(0))\n",
    "    predicted_label = torch.argmax(prediction)\n",
    "    predicted_label_name = viz_dataset.class_names[predicted_label]\n",
    "    actual_label_name = viz_dataset.class_names[label]\n",
    "    # image = inverse_normalize(image) * 255\n",
    "    ax[0, i].imshow(image.permute(1, 2, 0).short().cpu())\n",
    "    ax[0, i].set_title(f\"actual: {actual_label_name}\\npred: {predicted_label_name}\")\n",
    "    ax[0, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create OpenVINO Model\n",
    "\n",
    "To create an OpenVINO IR model, we convert the PyTorch model to ONNX, and then use the OpenVINO model optimizer to convert the ONNX model to an IR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelname_xml = MODELNAME + \".xml\"\n",
    "modelname_onnx = MODELNAME + \".onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 299, 299)\n",
    "torch.onnx.export(model.model.cpu(), dummy_input, modelname_onnx, opset_version=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create OpenVINO IR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subprocess.run(\n",
    "    [\n",
    "        \"mo\",\n",
    "        \"--model_name\",\n",
    "        MODELNAME,\n",
    "        \"--input_model\",\n",
    "        modelname_onnx,\n",
    "        \"--input_shape\",\n",
    "        f\"{(1,3,*IMAGE_SHAPE)}\",\n",
    "        \"--output_dir\",\n",
    "        os.path.abspath(os.curdir),\n",
    "        \"--data_type\",\n",
    "        \"FP16\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do inference and show predictions\n",
    "\n",
    "We create two helper functions, `load_to_IE` and `do_inference` to load the IR model and perform inference. \n",
    "\n",
    "We then load the model, do inference on the test dataset, and show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_to_IE(modelname_xml):\n",
    "    \"\"\"\n",
    "    Load a given IR model to Inference Engine\n",
    "\n",
    "    :param modelname_xml: Filename to IR model XML file. The accompanying IR bin file is expected to be in the same directory.\n",
    "    \"\"\"\n",
    "    ie = IECore()  # Load the Inference Engine API\n",
    "    net = ie.read_network(model=modelname_xml, weights=modelname_xml.replace(\"xml\", \"bin\"))\n",
    "    exec_net = ie.load_network(\n",
    "        network=net, device_name=\"CPU\"\n",
    "    )  # Load the network to the inference engine\n",
    "    return exec_net\n",
    "\n",
    "\n",
    "def do_inference(exec_net, image):\n",
    "    input_blob = next(iter(exec_net.input_info))\n",
    "    output_key = next(iter(exec_net.outputs))\n",
    "    return exec_net.infer({input_blob: image})[output_key]\n",
    "\n",
    "\n",
    "openvino_model = load_to_IE(modelname_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viz_dataset = data.dataset_val\n",
    "num = min(len(viz_dataset), 6)\n",
    "indices = np.random.choice(range(len(viz_dataset)), num, replace=False)\n",
    "\n",
    "fig, ax = plt.subplots(1, num, figsize=(20, 5), squeeze=False)\n",
    "for i, index in enumerate(indices):\n",
    "    image, label = viz_dataset[index]\n",
    "    input_image = image.unsqueeze(0).float().numpy().copy()\n",
    "    prediction = do_inference(openvino_model, input_image)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    predicted_label_name = viz_dataset.class_names[predicted_label]\n",
    "    actual_label_name = viz_dataset.class_names[label]\n",
    "\n",
    "    # display_image = inverse_normalize(image) * 255\n",
    "    ax[0, i].imshow(image.permute(1, 2, 0).short().cpu())\n",
    "\n",
    "    ax[0, i].set_title(f\"actual: {actual_label_name}\\npred: {predicted_label_name}\")\n",
    "\n",
    "    ax[0, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare PyTorch and OpenVINO accuracy and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute accuracy for PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num = 1000\n",
    "indices = random.sample(range(len(data.dataset_val)), num)\n",
    "data_subset = itemgetter(*indices)(data.dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "model.cuda().eval()\n",
    "\n",
    "for i, (image, label) in enumerate(data_subset):\n",
    "    input_image = image.unsqueeze(0).float()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_image.cuda())\n",
    "    predicted_label = torch.argmax(prediction.cpu())\n",
    "    true_labels.append(label.item())\n",
    "    predicted_labels.append(predicted_label.item())\n",
    "\n",
    "torch_score = skm.accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Accuracy for PyTorch model: {torch_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute accuracy for OpenVINO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for i, (image, label) in enumerate(data_subset):\n",
    "    image = copy.deepcopy(image)\n",
    "    input_image = image.unsqueeze(0).float().numpy().copy()\n",
    "    prediction = do_inference(openvino_model, input_image)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    true_labels.append(label.item())\n",
    "    predicted_labels.append(predicted_label.item())\n",
    "\n",
    "openvino_score = skm.accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f\"Accuracy for OpenVINO model: {openvino_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Inference speed\n",
    "\n",
    "This gives an initial impression. The OpenVINO speed can be improved by using the Datumaro dataset directly and optimizing the model. CPU info is displayed for context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenVINO on CPU (with PyTorch dataset)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "for i, (image, label) in enumerate(data_subset):\n",
    "    input_image = image.unsqueeze(0).float().numpy().copy()\n",
    "    prediction = do_inference(openvino_model, input_image)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "duration = end_time - start_time\n",
    "print(f\"{duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyTorch on CPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "model.cpu().eval()\n",
    "for i, (image, label) in enumerate(data_subset):\n",
    "    with torch.no_grad():\n",
    "        prediction = model.model(image.unsqueeze(0).cpu())\n",
    "    predicted_label = torch.argmax(prediction)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "duration = end_time - start_time\n",
    "print(f\"{duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyTorch on GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.has_cuda:\n",
    "    model.cuda().eval()\n",
    "    start_time = time.perf_counter()\n",
    "    for i, (image, label) in enumerate(data_subset):\n",
    "        with torch.no_grad():\n",
    "            prediction = model.model(image.unsqueeze(0).cuda())\n",
    "        predicted_label = torch.argmax(prediction)\n",
    "    end_time = time.perf_counter()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"{duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
