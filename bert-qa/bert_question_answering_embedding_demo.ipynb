{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "domestic-wrapping",
   "metadata": {},
   "source": [
    "# BERT Question Answering Embedding Demo\n",
    "\n",
    "This notebook demonstrates a Question Answering demo application that uses a SQuAD-tuned BERT model from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/) to calculate embedding vectors to find the right context for questions. See `bert_embedding_demo.py` in the same folder as this notebook for the source code to load the model and perform inference.\n",
    "\n",
    "The primary difference from the [bert_question_answering_demo](../../../bert_question_answering_demo/README.md) is that this demo demonstrates how the inference can be accelerated via pre-computing the embeddings for the contexts. \n",
    "\n",
    "## How It Works\n",
    "\n",
    "The model is loaded to OpenVINO Inference Engine. Data is fetched from the user-provided url to populate the list of \"contexts\" with the text. Prior to the actual inference to answer user's questions, the embedding vectors are pre-calculated (via inference) for each context from the list. This is done using the first (\"emdbeddings-only\") BERT model. After that, when user type the question and the \"embeddings\" network is used to calculate an embedding vector for the specified question. Using the L2 distance between the embedding vector of the question and the embedding vectors for the contexts the best (closest) contexts are selected as candidates to further seek for the final answer to the question. \n",
    "\n",
    "The question is usually much shorter than the contexts, so calculating the embedding for that is really fast. Also calculating the L2 distance between a context and question is almost free, compared to the actual inference. Together, during question answering, this substantially saves on the actual inference, which is needed ONLY for the question (while contexts are pre-calculated), compared to the conventional approach that has to concatenate each context with the question and do an inference on this large input (per context).\n",
    "\n",
    "A second (conventional SQuAD-tuned) Bert model is used to further search for the exact answer in the best contexts found in the first step.\n",
    "\n",
    "## Settings and Imports\n",
    "\n",
    "Change the `input_url` to change the context of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from bert_embedding_demo import BERT\n",
    "from bert_notebook_utils import BERT as ORIGINAL_BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_url = \"https://en.wikipedia.org/wiki/Bert_(Sesame_Street)\"\n",
    "\n",
    "# Other settings (only change this if you know what you are doing!)\n",
    "model_name_emb = \"bert-small-uncased-whole-word-masking-squad-emb-int8-0001\"\n",
    "model_name_qa = \"bert-small-uncased-whole-word-masking-squad-0001\"\n",
    "device = \"CPU\"\n",
    "reshape = False  # Try to reshape the sequence length to the input context + max question len (to improve the speed)\n",
    "model_squad_ver = \"1.2\"  # SQuAD version used for model fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file and directory paths for model. By default, this demo notebook downloads all BERT models from the Open Model Zoo and stores them in the current directory.\n",
    "# Adjust these settings if you want to change this.\n",
    "vocab_file = \"vocab.txt\"\n",
    "base_model_dir = os.curdir\n",
    "omz_cache_dir = os.path.expanduser(\"~/open_model_zoo_cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-lighting",
   "metadata": {},
   "source": [
    "## Download BERT Models\n",
    "\n",
    "Download BERT models from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/) with the Model Downloader. Models are downloaded to `base_model_dir`, which is set to the current directory by default. Open Model Zoo caches the downloaded models in `omz_cache_dir`. By default this is set to `open_model_zoo_cache` in the home directory (`/home/username` on Linux, `c:\\Users\\username` on Windows). If you want to modify these defaults, change the settings in the previous cell. See the [Model Downloader documentation](https://github.com/openvinotoolkit/open_model_zoo/blob/master/tools/downloader/README.md) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader_model_name = \"bert*\"  # Name (with optional wildcards) of the model or models to download. `bert*` downloads all BERT models. To only download the smaller models, set `downloader_model_name` to `bert-small*`\n",
    "precision = \"FP16,FP16-INT8\"  # If Model Downloader is run with the precision argument, only models with the specified precision are downloaded. On CPU, FP16 and FP32 give the same result.\n",
    "\n",
    "downloader_model_name = \"bert*\"\n",
    "! omz_downloader --name \"$downloader_model_name\" --jobs 4 --cache_dir $omz_cache_dir --precision $precision --output_dir $base_model_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-youth",
   "metadata": {},
   "source": [
    "## Setup BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BERT(\n",
    "    input_url=input_url,\n",
    "    vocab_file=vocab_file,\n",
    "    model_name_emb=model_name_emb,\n",
    "    model_name_qa=model_name_qa,\n",
    "    base_model_dir=base_model_dir,\n",
    "    reshape=reshape,\n",
    "    device=device,\n",
    "    model_squad_ver=model_squad_ver,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-sunset",
   "metadata": {},
   "source": [
    "## Ask Questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.ask(\"What is BERT?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-sphere",
   "metadata": {},
   "source": [
    "# Compare Embedding Model with Original Model\n",
    "\n",
    "Check the speed and result of the `ask` function on different models. Call `bert.ask` with `show_embeddings=False` and `show_context=False` for more concise output. Optionally set `show_answers` to `False` to disable all output. Note that the reported speeds are an indication. See the [OpenVINO documentation](https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Intro_to_Performance.html) for tips on how to improve performance and the [Benchmark C++ Sample](https://docs.openvinotoolkit.org/latest/_inference_engine_samples_benchmark_app_README.html) for actual performance measurements.\n",
    "\n",
    "Supported embedding models (`model_name_emb`):\n",
    "* bert-large-uncased-whole-word-masking-squad-emb-0001\n",
    "* bert-small-uncased-whole-word-masking-squad-emb-int8-0001\n",
    "\n",
    "Supported QA models (`model_name_qa`):\n",
    "* bert-large-uncased-whole-word-masking-squad-0001\n",
    "* bert-large-uncased-whole-word-masking-squad-int8-0001\n",
    "* bert-small-uncased-whole-word-masking-squad-0001\n",
    "* bert-small-uncased-whole-word-masking-squad-0002\n",
    "* bert-small-uncased-whole-word-masking-squad-int8-000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_qa = \"bert-large-uncased-whole-word-masking-squad-0001\"\n",
    "model_name_emb = \"bert-large-uncased-whole-word-masking-squad-emb-0001\"\n",
    "model_name_qa = \"bert-small-uncased-whole-word-masking-squad-0001\"\n",
    "model_name_emb = \"bert-small-uncased-whole-word-masking-squad-emb-int8-0001\"\n",
    "\n",
    "input_url = \"https://en.wikipedia.org/wiki/Sesame_Street\"\n",
    "questions = [\n",
    "    \"Who created Sesame Street?\",\n",
    "    \"What characters are in Sesame Street?\",\n",
    "    \"Where is Sesame Street?\",\n",
    "    \"When did Sesame Street start?\",\n",
    "    \"What is the goal of Sesame Street?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_bert = ORIGINAL_BERT(\n",
    "    input_url,\n",
    "    vocab_file,\n",
    "    model_name_qa,\n",
    "    base_model_dir,\n",
    "    reshape,\n",
    "    device,\n",
    "    model_squad_ver,\n",
    ")\n",
    "start_time_orig = time.time()\n",
    "original_bert.ask(questions, show_answers=True, show_context=False)\n",
    "end_time_orig = time.time()\n",
    "del original_bert\n",
    "print(f\"Original model time: {end_time_orig - start_time_orig:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_bert = BERT(\n",
    "    input_url,\n",
    "    vocab_file,\n",
    "    model_name_emb,\n",
    "    model_name_qa,\n",
    "    base_model_dir,\n",
    "    reshape=reshape,\n",
    "    device=device,\n",
    "    model_squad_ver=model_squad_ver,\n",
    ")\n",
    "start_time_emb = time.time()\n",
    "embedding_bert.ask(questions, show_answers=True, show_embeddings=False, show_context=False)\n",
    "end_time_emb = time.time()\n",
    "del embedding_bert\n",
    "print(f\"Embedding model time: {end_time_emb - start_time_emb:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aee205-90ac-49c2-93e7-5b0fbfd895a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
